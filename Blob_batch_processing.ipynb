{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trucabrac/blob_Jan2022/blob/main/Blob_batch_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj2nFAsjyJxu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from skimage.filters import gaussian\n",
        "from skimage import img_as_ubyte\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRvXuxf6zWQM"
      },
      "source": [
        "#1. Read images and store them in an array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyNFAh-o14VX",
        "outputId": "223164f2-73a2-4245-9220-e5a03a15a591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/blob-tl\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/blob-tl/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tl-selec/tl10/\n",
        "#%cd ../tl9/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipi3kgOJPW0f",
        "outputId": "35c58435-cf95-4079-e98f-a3ab0958f824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/blob-tl/tl-selec/tl10\n",
            "tl10-018.jpeg  tl10-126.jpeg  tl10-207.jpeg  tl10-315.jpeg\n",
            "tl10-045.jpeg  tl10-153.jpeg  tl10-234.jpeg  tl10-342.jpeg\n",
            "tl10-072.jpeg  tl10-180.jpeg  tl10-261.jpeg  tl10-369.jpeg\n",
            "tl10-099.jpeg  tl10-200.jpeg  tl10-288.jpeg  tl10-396.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYL-6R9Wxs8P",
        "outputId": "245f446f-4baf-4c35-d2bc-c3e2958aa836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tl10-018.jpeg\n",
            "tl10-045.jpeg\n",
            "tl10-072.jpeg\n",
            "tl10-099.jpeg\n",
            "tl10-126.jpeg\n",
            "tl10-153.jpeg\n",
            "tl10-180.jpeg\n",
            "tl10-200.jpeg\n",
            "tl10-207.jpeg\n",
            "tl10-234.jpeg\n",
            "tl10-261.jpeg\n",
            "tl10-288.jpeg\n",
            "tl10-315.jpeg\n",
            "tl10-342.jpeg\n",
            "tl10-369.jpeg\n",
            "tl10-396.jpeg\n"
          ]
        }
      ],
      "source": [
        "#################################################\n",
        "#Capture all mages into an array and then iterate through each image\n",
        "#Normally used for machine learning workflows.\n",
        "\n",
        "images_list = []\n",
        "images_names = []\n",
        "SIZE = 512\n",
        "\n",
        "path = \"*.*\"\n",
        "#pathOut = \"test-clas/\"\n",
        "pathOut = \"../tl-contour/\" #folder to create beforehand\n",
        "#path = \"tl4-proc/*.*\"\n",
        "#pathOut = \"tl4-clas/\"\n",
        "#label = 'tl4-'\n",
        "\n",
        "#First create a stack array of all images\n",
        "for file in glob.glob(path):\n",
        "    print(file)     #just stop here to see all file names printed\n",
        "    img0= cv2.imread(file, 0)  #now, we can read each file since we have the full path\n",
        "    #img = cv2.cvtColor(imgIn, cv2.IMREAD_GRAYSCALE)\n",
        "    #img = cv2.resize(img, (SIZE, SIZE))\n",
        "    images_list.append(img0)\n",
        "    images_names.append(file)\n",
        "        \n",
        "images_list = np.array(images_list)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNgvpLkbyUkT"
      },
      "source": [
        "#2. Import Keras ImageNet models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fWrwLPFyYvt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0DY8eO58nK"
      },
      "source": [
        "#3. Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-SZke_P5_Rg"
      },
      "outputs": [],
      "source": [
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "def getContours(im,word):\n",
        "  (hc, wc) = im.shape[:2]\n",
        "  x1 = wc/2\n",
        "  x2=wc/2\n",
        "  y1=hc/2\n",
        "  y2=hc/2\n",
        "  \n",
        "  contours,hierarchy = cv2.findContours(im, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "  for cnt in contours:\n",
        "    area= cv2.contourArea(cnt)\n",
        "    if area>0:\n",
        "      imgMid=cv2.drawContours(imgContour,cnt,-1,(0,255,0),3)\n",
        "      #peri = cv2.arcLength(cnt,True)\n",
        "      #approx = cv2.approxPolyDP(cnt,) \n",
        "    \n",
        "      #draw bounding rectangles\n",
        "      x,y,w,h = cv2.boundingRect(cnt)\n",
        "      if x < x1: x1 = x-20\n",
        "      if x+w > x2: x2 = x+w+20\n",
        "      if y < y1: y1 = y-20\n",
        "      if y+h > y2: y2 = y+h+20\n",
        "  imgFinal = cv2.rectangle(imgMid,(x1,y1),(x2,y2),(255,0,0),6)\n",
        "  cv2.putText(imgFinal, word, (x1, y1-20), font, 2, (255,0,0), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "#alternative without bounding box and word\n",
        "def getContours2(im):\n",
        "  (hc, wc) = im.shape[:2]\n",
        "  x1 = wc/2\n",
        "  x2=wc/2\n",
        "  y1=hc/2\n",
        "  y2=hc/2\n",
        "  \n",
        "  contours,hierarchy = cv2.findContours(im, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "  for cnt in contours:\n",
        "    area= cv2.contourArea(cnt)\n",
        "    if area>0:\n",
        "      imgMid=cv2.drawContours(imgContour,cnt,-1,(0,255,0),3)\n",
        "      #peri = cv2.arcLength(cnt,True)\n",
        "      #approx = cv2.approxPolyDP(cnt,) \n",
        "    \n",
        "  imgFinal = imgMid\n"
      ],
      "metadata": {
        "id": "NKisHMMd9wp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run just once when creating the csv\n",
        "f = open('/content/drive/MyDrive/blob-tl/blobtl-clas-prob-top3.csv', 'w')\n",
        "# create the csv writer\n",
        "writer = csv.writer(f)\n",
        "# write the header\n",
        "#header = ['imgpath', 'class']\n",
        "writer.writerow(['imgpath', 'class'])\n",
        "f.close()"
      ],
      "metadata": {
        "id": "t3ceiKMMU9-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the csv file in the write mode to store classifications\n",
        "f = open('/content/drive/MyDrive/blob-tl/blobtl-clas-prob-top3.csv', 'a')\n",
        "# create the csv writer\n",
        "writer = csv.writer(f)"
      ],
      "metadata": {
        "id": "RIy7STwtPTyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO1tuzz552mK"
      },
      "source": [
        "#4. Process each image -> classif + text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23KcTqVdx48A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "21900675-7cb2-41d6-b5a7-a5b541932002"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d9bba871710c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_GRAY2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocess_input' is not defined"
          ]
        }
      ],
      "source": [
        "#Process each image in the array\n",
        "img_number = 0\n",
        "for image in range(images_list.shape[0]):\n",
        "    inImg = images_list[image,:,:]  #Grey images. For color add another dim.\n",
        "    #smoothed_image = img_as_ubyte(gaussian(inImg, sigma=5, mode='constant', cval=0.0))\n",
        "\n",
        "    #preprocess img \n",
        "    dim = (224, 224)\n",
        "    sizImg = cv2.resize(inImg, dim, interpolation=cv2.INTER_LINEAR)\n",
        "    #cv2_imshow(sizImg)\n",
        "    x = cv2.cvtColor(sizImg, cv2.COLOR_GRAY2RGB)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "\n",
        "    #Classify with Keras models\n",
        "    #call randomly one of the models\n",
        "    nModel = random.randint(0,2)\n",
        "    if nModel==0:\n",
        "      model_vgg16 = VGG16(weights='imagenet')\n",
        "      preds = model_vgg16.predict(x)\n",
        "    if nModel==1:\n",
        "      model_rn50 = ResNet50(weights='imagenet')\n",
        "      preds = model_rn50.predict(x)\n",
        "    if nModel==2:\n",
        "      model_mobilenet = MobileNet(weights='imagenet')\n",
        "      preds = model_mobilenet.predict(x)\n",
        "    # decode the results into a list of tuples (class, description, probability)\n",
        "    # and choose 1 result randomly from the top20\n",
        "    pred_top = decode_predictions(preds, top=20)[0]\n",
        "    #print('Predicted:', pred_top)\n",
        "    topn = random.randint(0,19)\n",
        "    #print(topn)\n",
        "    pred_dis = pred_top[topn][1]\n",
        "    #print('Predicted:', pred_dis)\n",
        "\n",
        "    #find contours and draw bounding box in image\n",
        "    imgCanny = cv2.Canny(inImg,500,500)\n",
        "    #cv2_imshow(imgCanny)\n",
        "    imgContour = cv2.cvtColor(inImg, cv2.COLOR_GRAY2RGB)\n",
        "    getContours(imgCanny,pred_dis)\n",
        "    #cv2_imshow(imgContour)\n",
        "\n",
        "    imgPath = pathOut+label+str(img_number)\n",
        "    #save image with contour\n",
        "    cv2.imwrite(pathOut+label+str(img_number)+\".jpg\", imgContour)\n",
        "    #store img ref and class in csv\n",
        "    #writer.writerow([imgPath, pred_dis])\n",
        "\n",
        "    #increment\n",
        "    img_number +=1   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process images contours only\n",
        "#Process each image in the array\n",
        "img_number = 0\n",
        "label = 'test'\n",
        "for image in range(images_list.shape[0]):\n",
        "    inImg = images_list[image,:,:]  #Grey images. For color add another dim.\n",
        "    #smoothed_image = img_as_ubyte(gaussian(inImg, sigma=5, mode='constant', cval=0.0))\n",
        "\n",
        "    #find contours and draw them\n",
        "    imgCanny = cv2.Canny(inImg,300,300)\n",
        "    #cv2_imshow(imgCanny)\n",
        "    imgContour = cv2.cvtColor(inImg, cv2.COLOR_GRAY2RGB)\n",
        "    getContours2(imgCanny)\n",
        "    #cv2_imshow(imgContour)\n",
        "\n",
        "    #imgPath = pathOut+images_names[image]+str(img_number)\n",
        "    #save image with contour\n",
        "    #cv2.imwrite(pathOut+label+str(img_number)+\".jpg\", imgContour)\n",
        "    cv2.imwrite(pathOut+images_names[image], imgContour)\n",
        "    #store img ref and class in csv\n",
        "    #writer.writerow([imgPath, pred_dis])\n",
        "\n",
        "    #increment\n",
        "    img_number +=1   "
      ],
      "metadata": {
        "id": "1wnmcVGm-IhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Process Keras classifications only\n",
        "img_number = 0\n",
        "for image in range(images_list.shape[0]):\n",
        "    inImg = images_list[image,:,:]  #Grey images. For color add another dim.\n",
        "    #smoothed_image = img_as_ubyte(gaussian(inImg, sigma=5, mode='constant', cval=0.0))\n",
        "\n",
        "    #preprocess img \n",
        "    dim = (224, 224)\n",
        "    sizImg = cv2.resize(inImg, dim, interpolation=cv2.INTER_LINEAR)\n",
        "    #cv2_imshow(sizImg)\n",
        "    x = cv2.cvtColor(sizImg, cv2.COLOR_GRAY2RGB)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "\n",
        "    #Classify with Keras models\n",
        "    #call randomly one of the models\n",
        "    nModel = random.randint(0,2)\n",
        "    if nModel==0:\n",
        "      model_vgg16 = VGG16(weights='imagenet')\n",
        "      preds = model_vgg16.predict(x)\n",
        "    if nModel==1:\n",
        "      model_rn50 = ResNet50(weights='imagenet')\n",
        "      preds = model_rn50.predict(x)\n",
        "    if nModel==2:\n",
        "      model_mobilenet = MobileNet(weights='imagenet')\n",
        "      preds = model_mobilenet.predict(x)\n",
        "    # decode the results into a list of tuples (class, description, probability)\n",
        "    # and choose 1 result randomly from the top20\n",
        "    pred_top = decode_predictions(preds, top=3)[0]\n",
        "    #print('Predicted:', pred_top)\n",
        "    topn = random.randint(0,2)\n",
        "    #print(topn)\n",
        "    pred_dis = pred_top[topn][1]\n",
        "    pred_p = pred_top[topn][2] * 100\n",
        "    #print('Predicted:', pred_dis)\n",
        "\n",
        "    imgPath = pathOut+label+str(img_number)\n",
        "    proba = str(pred_p)+'%'\n",
        "    #save image with contour\n",
        "    #cv2.imwrite(pathOut+images_names[image]+\".jpg\", imgContour)\n",
        "    #store img ref and class in csv\n",
        "    writer.writerow([images_names[image], pred_dis, proba])\n",
        "\n",
        "    #increment\n",
        "    img_number +=1   "
      ],
      "metadata": {
        "id": "kLFqAvKefhdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a2c3fc-f19d-4737-9124-938c049ba35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n",
            "553476096/553467096 [==============================] - 3s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "49152/35363 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "17235968/17225924 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56b26bddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56b2611830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdKXfgJ4zN3C"
      },
      "outputs": [],
      "source": [
        "# close the file\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Blob -batch processing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+StrRl+JLfegDwHHJXzCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}